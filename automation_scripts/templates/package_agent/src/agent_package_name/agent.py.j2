import logging
import asyncio
import datetime
import uuid # Added uuid
# --- MODIFIED: Added Union, List, Dict, Any ---
from typing import Optional, AsyncGenerator, Union, List, Dict, Any
# --- END MODIFIED ---
import json # Added json

# SDK Imports
from agentvault_server_sdk import BaseA2AAgent, a2a_method
from agentvault_server_sdk.state import BaseTaskStore, TaskContext
from agentvault_server_sdk.exceptions import TaskNotFoundError

# Core Model Imports
# --- MODIFIED: Assume models are always available ---
from agentvault.models import (
    Message, Task, TaskState, A2AEvent, TextPart, TaskStatusUpdateEvent, TaskMessageEvent,
    Artifact, TaskArtifactUpdateEvent
)
# --- END MODIFIED ---
# --- ADDED: Import pydantic ---
import pydantic
# --- END ADDED ---

logger = logging.getLogger(__name__)

class {{ agent_name | replace(' ', '') | replace('-', '') }}Agent(BaseA2AAgent):
    """
    Boilerplate implementation for {{ agent_name }}.
    Replace this with your agent's actual logic.
    """
    def __init__(self, task_store_ref: BaseTaskStore):
        super().__init__(agent_metadata={"name": "{{ agent_name }}"})
        self.task_store = task_store_ref
        # --- ADDED: Background task tracking ---
        self._background_tasks: Dict[str, asyncio.Task] = {}
        # --- END ADDED ---
        logger.info("{{ agent_name }} initialized.")

    async def handle_task_send(self, task_id: Optional[str], message: Message) -> str:
        """Handle task initiation or continuation."""
        logger.info(f"Handling task send: task_id={task_id}")
        if task_id:
            task_context = await self.task_store.get_task(task_id)
            if task_context is None: raise TaskNotFoundError(task_id=task_id)
            # TODO: Add logic for handling subsequent messages if needed
            # For simple echo, we might just restart processing or ignore
            logger.warning(f"Received message for existing task {task_id}. Simple agent example will re-process.")
            # Optionally cancel existing background task if needed
            if task_id in self._background_tasks and not self._background_tasks[task_id].done():
                self._background_tasks[task_id].cancel()
            bg_task = asyncio.create_task(self._process_task(task_id, message))
            self._background_tasks[task_id] = bg_task
            bg_task.add_done_callback(lambda fut: self._background_tasks.pop(task_id, None))
            return task_id
        else:
            # --- MODIFIED: Use UUID for task ID ---
            new_task_id = f"task-{{ package_name[:8] }}-{uuid.uuid4().hex[:8]}"
            # --- END MODIFIED ---
            await self.task_store.create_task(new_task_id)
            # Start background processing after creation
            bg_task = asyncio.create_task(self._process_task(new_task_id, message))
            self._background_tasks[new_task_id] = bg_task
            # Optional: Add callback to remove task from dict when done
            bg_task.add_done_callback(
                lambda fut: self._background_tasks.pop(new_task_id, None)
            )
            return new_task_id

    async def handle_task_get(self, task_id: str) -> Task:
        """Retrieve task status."""
        logger.info(f"Handling task get: task_id={task_id}")
        task_context = await self.task_store.get_task(task_id)
        if task_context is None: raise TaskNotFoundError(task_id=task_id)

        # --- MODIFIED: Removed _MODELS_AVAILABLE check ---
        # Construct Task model from TaskContext
        # Note: Message/artifact history needs to be stored separately or in extended context
        current_state_enum = task_context.current_state if isinstance(task_context.current_state, TaskState) else TaskState(task_context.current_state)
        messages_to_return = getattr(task_context, 'messages', []) # Assumes extended context might have messages
        return Task(
            id=task_context.task_id,
            state=current_state_enum,
            createdAt=task_context.created_at,
            updatedAt=task_context.updated_at,
            messages=messages_to_return, # Placeholder or from extended context
            artifacts=[], # Placeholder
            metadata={"agent_name": self.agent_metadata.get("name")}
        )
        # --- END MODIFIED ---

    async def handle_task_cancel(self, task_id: str) -> bool:
        """Handle task cancellation request."""
        logger.info(f"Handling task cancel: task_id={task_id}")
        task_context = await self.task_store.get_task(task_id)
        if task_context is None: raise TaskNotFoundError(task_id=task_id)

        terminal_states = {TaskState.COMPLETED, TaskState.FAILED, TaskState.CANCELED}
        current_state = task_context.current_state
        # --- MODIFIED: Removed _MODELS_AVAILABLE check ---
        if isinstance(current_state, str):
             current_state = TaskState(current_state) # Convert if needed
        # --- END MODIFIED ---

        if current_state not in terminal_states:
            # Cancel background task if it's running
            bg_task = self._background_tasks.pop(task_id, None)
            if bg_task and not bg_task.done():
                bg_task.cancel()
                logger.info(f"Cancelled background processing task for {task_id}")

            await self.task_store.update_task_state(task_id, TaskState.CANCELED)
            logger.info(f"Task {task_id} marked as canceled.")
            return True
        else:
            logger.warning(f"Task {task_id} already in terminal state {task_context.current_state}.")
            return False # Cannot cancel

    # --- MODIFIED: Correct handle_subscribe_request implementation ---
    async def handle_subscribe_request(self, task_id: str) -> AsyncGenerator[bytes, None]:
        """Stream task updates via SSE by listening to the task store and formatting."""
        logger.info(f"Handling subscribe request: task_id={task_id}")
        listener_queue: asyncio.Queue[A2AEvent] = asyncio.Queue()
        await self.task_store.add_listener(task_id, listener_queue)
        logger.debug(f"Listener queue added for task {task_id}")

        is_terminal = False
        try:
            # Yield initial state immediately? Optional.
            task_context = await self.task_store.get_task(task_id)
            if task_context is None:
                logger.warning(f"Task {task_id} disappeared before initial state yield.")
                raise TaskNotFoundError(task_id) # Raise error if task gone immediately

            # --- MODIFIED: Removed _MODELS_AVAILABLE check ---
            initial_event = TaskStatusUpdateEvent(
                taskId=task_id,
                state=task_context.current_state, # type: ignore
                timestamp=task_context.updated_at
            )
            logger.debug(f"Yielding initial state for {task_id}: {initial_event.state}")
            # Format and yield the initial event
            formatted_event = self._format_sse_event(initial_event)
            if formatted_event:
                yield formatted_event
            # --- END MODIFIED ---

            # Loop, yielding events from the queue until task is terminal
            while not is_terminal:
                try:
                    # Wait for an event from the background task via the store's queue
                    event = await asyncio.wait_for(listener_queue.get(), timeout=1.0) # Use timeout
                    logger.debug(f"Received event from queue for {task_id}: {type(event).__name__}")

                    # Format and yield the received event
                    formatted_event = self._format_sse_event(event)
                    if formatted_event:
                        yield formatted_event

                    listener_queue.task_done()

                    # Check if the event indicates a terminal state
                    if isinstance(event, TaskStatusUpdateEvent):
                        terminal_states = {TaskState.COMPLETED, TaskState.FAILED, TaskState.CANCELED}
                        if event.state in terminal_states:
                            logger.info(f"Task {task_id} reached terminal state ({event.state}) via SSE event. Ending stream.")
                            is_terminal = True
                            break # Exit loop

                except asyncio.TimeoutError:
                    # Timeout occurred, check task state directly from store
                    logger.debug(f"SSE listener timeout for {task_id}, checking state...")
                    task_context = await self.task_store.get_task(task_id)
                    if task_context is None:
                        logger.warning(f"Task {task_id} disappeared during subscription wait.")
                        is_terminal = True
                        break
                    terminal_states = {TaskState.COMPLETED, TaskState.FAILED, TaskState.CANCELED}
                    current_state = task_context.current_state
                    # --- MODIFIED: Removed _MODELS_AVAILABLE check ---
                    if isinstance(current_state, str):
                        current_state = TaskState(current_state)
                    # --- END MODIFIED ---
                    if current_state in terminal_states:
                        logger.info(f"Task {task_id} reached terminal state ({current_state}) during timeout check. Ending stream.")
                        is_terminal = True
                        break
                    # Otherwise, continue waiting for events

        except TaskNotFoundError:
             logger.warning(f"Task {task_id} not found during subscription.")
             # Generator stops implicitly
        except asyncio.CancelledError:
             logger.info(f"Subscription for task {task_id} cancelled by client.")
             # Generator stops implicitly
        except Exception as e:
             logger.exception(f"Error in subscribe generator for task {task_id}: {e}")
             # Optionally yield an error event?
             try:
                 error_data = json.dumps({"error": "stream_error", "message": f"Error generating events: {type(e).__name__}: {str(e)}"})
                 yield f"event: error\ndata: {error_data}\n\n".encode('utf-8')
             except Exception as format_err:
                 logger.error(f"Failed to yield SSE error event: {format_err}")
        finally:
            logger.info(f"Removing listener queue and ending subscription stream for task {task_id}")
            await self.task_store.remove_listener(task_id, listener_queue)

    def _format_sse_event(self, event: A2AEvent) -> Optional[bytes]:
        """Helper to format an A2AEvent into SSE message bytes."""
        event_type: Optional[str] = None
        # --- MODIFIED: Removed _MODELS_AVAILABLE check ---
        if isinstance(event, TaskStatusUpdateEvent): event_type = "task_status"
        elif isinstance(event, TaskMessageEvent): event_type = "task_message"
        elif isinstance(event, TaskArtifactUpdateEvent): event_type = "task_artifact"
        # --- END MODIFIED ---

        if event_type is None:
            logger.warning(f"Cannot format unknown event type: {type(event)}")
            return None

        try:
            # --- MODIFIED: Removed _MODELS_AVAILABLE check ---
            if hasattr(event, 'model_dump_json'):
                 json_data = event.model_dump_json(by_alias=True)
            else:
                 json_data = json.dumps(event if isinstance(event, dict) else {"data": str(event)})
            # --- END MODIFIED ---
            sse_message = f"event: {event_type}\ndata: {json_data}\n\n"
            return sse_message.encode("utf-8")
        except Exception as e:
            logger.error(f"Failed to serialize or format SSE event (type: {event_type}): {e}", exc_info=True)
            return None
    # --- END MODIFIED ---

    async def _process_task(self, task_id: str, initial_message: Message):
        """Placeholder for the agent's background processing logic."""
        logger.info(f"Starting background processing for task {task_id}")
        try:
            # 1. Set state to WORKING (will notify listeners via store)
            await self.task_store.update_task_state(task_id, TaskState.WORKING)
            await asyncio.sleep(1) # Simulate work

            # 2. Process the message (simple echo for boilerplate)
            input_text = "No text found in initial message"
            if initial_message.parts and isinstance(initial_message.parts[0], TextPart):
                input_text = initial_message.parts[0].content

            response_text = f"Agent '{self.agent_metadata.get('name', 'Unknown')}' processed: {input_text}"
            response_message = Message(role="assistant", parts=[TextPart(content=response_text)])

            # 3. Notify message event (will notify listeners via store)
            await self.task_store.notify_message_event(task_id, response_message)
            await asyncio.sleep(1) # Simulate more work

            # 4. Set state to COMPLETED (will notify listeners via store)
            await self.task_store.update_task_state(task_id, TaskState.COMPLETED)
            logger.info(f"Successfully completed processing task {task_id}")

        except Exception as e:
            logger.exception(f"Error processing task {task_id}")
            try:
                # Attempt to notify FAILED state (will notify listeners via store)
                await self.task_store.update_task_state(task_id, TaskState.FAILED, message=f"Processing error: {e}")
            except Exception as notify_err:
                logger.error(f"Failed to notify FAILED state for task {task_id}: {notify_err}")

    # --- Example Decorated Method ---
    # @a2a_method("custom/get_info")
    # async def get_agent_info(self) -> dict:
    #     """Returns basic agent metadata."""
    #     return self.agent_metadata
